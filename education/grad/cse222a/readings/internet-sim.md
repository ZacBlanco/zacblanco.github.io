---
layout: page
---

## Introduction

- acknowledge dangers, pitfalls, limitations of internet simulations
- measurement of internet required as a "reality check"
- experiments vital for dealing with implementation issues
- simulations are good for preventing a "success disaster"
    - the propagation of software across the internet which is poorly (or could
      be better-designed) which results in suboptimal performance
- simulations are good for examining particular aspects of proposed changes
    - no single suite that encompasses everything
- simulations not good for face values numbers (e.g. speed of protocol A vs B)


## An Immense Moving Target

- internet is growing exponentially YoY
- number of bytes being moved is also changing
- exercise caution in assumptions about observations made at a particular point
  drawing meaning to another point in time

## Heterogeneity

- topology and link properties
    - in simulation: which topology to use? how are links connected? properties
      of links?
    - topology is constantly changing
    - engineered by competing entities
    - properties of links are known, but the parameters span a large range
        - modems w/ hundreds of bytes/s vs fiber links
    - routing changes regularly on the internet -- simulation probably needs to
      include "multi-pathing"
- protocol differences
    - different implementations of the same protocol (TCP) results in different
      connection performance
- traffic generation
    - need many, many sources to mimic internet traffic
    - could use internet traces to get good representation -- but in the real
      world with congestion, clients cut send rates to reduce bandwidth during
      congestion
    - often application traces are more useful in creating a realistic scenario
      than a packet-driven framework
    - not all sources can be characterized by traffic traces
        - user behavior changes depending on traffic conditions. Need to have a
          deeper understanding of traffic to model this
    - atypical drop rates is somewhat common. Modeling this behavior is not
      understood.

## Today's Network is not Tomorrow's

- areas of change
    - pricing structure
    - scheduling
    - wireless
    - impoverished devices (handhelds)
    - web caching
    - multicast
    - "killer apps"

##  Coping Strategies

- invariants: some property that holds empirically for a wide range of scenarios
    - e.g.:
        - diurnal activity patterns
        - self-similarity: long term correlations in packet arrivals are
          described as "fractal" or "self-similar"
        - poisson session arrivals
        - log-normal connection sizes: logarithm of sizes is approximated well
          with gaussian distribution
        - heavy-tailed distributions
            - characterizing network activity, expect to find heavy tails (high
              variance)
        - invariant distribution for telnet packet generation
            - distribution of network packets generated by telnet session is
              invariant --> keystrokes can probably be modeled as an exponential
              distribution
        - invariant characteristics of global topology:
            - there are 7 continents, speed of light, distance between NY/Paris, etc
